{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Browsing Selection of Ungulates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a pipeline which produces estimates of ungulate browsing selection in a forested area.\n",
    "\n",
    "The pipeline consists of the following steps:\n",
    "\n",
    "1. [Loading preliminaries](#1)\n",
    "2. [Loading the dataset](#2)\n",
    "3. [Generating estimates](#3)\n",
    "4. [Displaying results](#4)\n",
    "\n",
    "Each of the steps are described in more detail below. To use the notebook, please save the woody plant supply data on the forested area in question to the same folder as this notebook and in the format described in the second section. Afterwards, please hit *Run all cells* and, once the notebook has finished running, find the output of the prediction in the last section of the notebook as well as in a file saved in the same directory as this notebook under the name *browsing_forecast.csv*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading preliminaries <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "The cell below loads packages which are required for the computations in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import joblib\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "\n",
    "from typing import Dict, Union\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell loads some auxilliary functionality which is utilized later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_TS(X:np.ndarray) -> np.ndarray:\n",
    "    '''Normalizes the TS columns of a predictor array.\n",
    "    :param: X: the array which contains the columns to normalize.\n",
    "    :return: the complete array in which the TS columns are now normalized.'''\n",
    "\n",
    "    X_normalized = X.copy()\n",
    "\n",
    "    cols_to_normalize = [i for i in range(np.shape(X)[1]) if i % 3 == 0]\n",
    "\n",
    "    smoothing = 0.00001     # Applied so that 0 division does not cause any problems while normalizing.\n",
    "\n",
    "    X_normalized[:, cols_to_normalize] = (X[:, cols_to_normalize] - (X[:, cols_to_normalize].min(axis=0))) \\\n",
    "                            / (X[:, cols_to_normalize].max(axis=0) - (X[:, cols_to_normalize].min(axis=0)) + smoothing)\n",
    "    \n",
    "    return X_normalized\n",
    "\n",
    "def adjust_predictions(y_pred:np.ndarray, X:np.ndarray, noSupply_value:float) -> np.ndarray:\n",
    "    '''Ensures that the specified noSupply_value is predicted whenever there is no shoot supply\n",
    "    and that there are no negative predictions when there IS supply.\n",
    "    :param: y_pred: the array of original predictions.\n",
    "    :param: X: the array of predictors.\n",
    "    :param: noSupply_value: the value to predict in case of no supply.\n",
    "    :return: the adjusted array of predictions.\n",
    "    '''\n",
    "\n",
    "    y_pred_adjusted = y_pred.copy()\n",
    "\n",
    "    for i in range(y_pred.shape[0]):\n",
    "            for j in range(y_pred.shape[1]):\n",
    "                if X[i, j * 3] == 0:\n",
    "                    y_pred_adjusted[i, j] = noSupply_value\n",
    "\n",
    "                elif y_pred[i, j] < 0:\n",
    "                    y_pred_adjusted[i, j] = 0\n",
    "\n",
    "    return y_pred_adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the dataset <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline allows you to generate browsing estimates based on the available plant supply in a forested area. For this purpose, you need to have data saved on the plant supply in the same folder as this notebook. The data should be in an Excel file named `forest_data.xlsx`, and it should be in the following format:\n",
    "\n",
    "* The worksheet containing the data should be the only sheet in the Excel file.\n",
    "\n",
    "* The table in the worksheet should contain exactly 27 columns.\n",
    "\n",
    "* The table can have an arbitrary number of rows, each of which represents a point within the forest in question. The rows should be ordered so that the points follow each other as they would along a transect in the forest (i.e., adjacent points in the forest should be in adjacent rows).\n",
    "\n",
    "* Please make sure that the number of rows (i.e., the number of sampling points) is a multiple of 5. This is because the sampling points will be aggregated into sections of the forest, each of which should comprise 5 sampling points, in order to help the performance of the predictive models.\n",
    "\n",
    "* Each of the 27 columns should contain the total number of shoots found of a given species at the sampling point contained in the specific row. The columns should correspond to the following species **in the exact same order**:\n",
    "\n",
    "    1. Unknown species\n",
    "    2. Quercus petraea\n",
    "    3. Quercus cerris\n",
    "    4. Fraxinus excelsior\n",
    "    5. Fraxinus ornus\n",
    "    6. Carpinus betulus\n",
    "    7. Fagus sylvatica\n",
    "    8. Acer pseudoplatanus\n",
    "    9. Acer platanoides\n",
    "    10. Acer campestre\n",
    "    11. Pinus sylvestris\n",
    "    12. Robinia pseudoacacia\n",
    "    13. Ligustrum vulgare\n",
    "    14. Crataegus monogyna\n",
    "    15. Cornus mas\n",
    "    16. Cornus sanguinea\n",
    "    17. Prunus spinosa\n",
    "    18. Rubus fruticosus\n",
    "    19. Rosa canina\n",
    "    20. Acer tataricum\n",
    "    21. Prunus avium\n",
    "    22. Corylus avellana\n",
    "    23. Ulmus minor \n",
    "    24. Sorbus aucuparia\n",
    "    25. Pyrus pyraster\n",
    "    26. Euonymus verrucosus\n",
    "    27. Quercus pubescens\n",
    "    \n",
    "    <br>\n",
    "* The first row of the table should contain the names of the species as headers. The numeric values should start in the **second row** of the Excel sheet.\n",
    "\n",
    "You can find an example of such a file contained in the folder named *Example*. You can use it as a template to create your own file containing woody plant supply data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells use this file to load the dataset and calculate frequency (F) and relative proportion of supply (RPS) values for each of the species. Afterwards, the sampling points are aggregated by fives so that these aggregated instances represent sections of the forest instead of points, which, as mentioned above, helps the performance of the machine learning models. The processed dataset will be saved in the variable named `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data and saving total shoots (TS) values as well as all species names.\n",
    "\n",
    "loaded_dataset = pd.read_excel('forest_data.xlsx')\n",
    "\n",
    "ts_values = loaded_dataset.values\n",
    "\n",
    "species = loaded_dataset.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating distribution properties frequency (F) and relative proportion of supply (RPS) for each species.\n",
    "\n",
    "# A table is created, where for each species these properties are stored.\n",
    "# The first row contains the species names, the second the F and the third the RPS values.\n",
    "\n",
    "sampling_points = len(ts_values)\n",
    "all_shoots = 0\n",
    "\n",
    "nr_species = len(species)\n",
    "\n",
    "properties_table = np.concatenate((species[np.newaxis, :].astype(object), np.zeros((2, nr_species))))\n",
    "\n",
    "for i in range(1,len(ts_values)):\n",
    "    for j in range(nr_species):\n",
    "        ts = ts_values[i, j]\n",
    "            \n",
    "        if ts != 0:\n",
    "            properties_table[1,j] += 1\n",
    "            properties_table[2,j] += ts\n",
    "\n",
    "            all_shoots += ts\n",
    "    \n",
    "#Normalizing species data with nr of sampling points / shoots in the forest.\n",
    "properties_table[1, :] = properties_table[1, :] / sampling_points\n",
    "properties_table[2, :] = properties_table[2, :] / all_shoots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataset table where F and RPS values are included along with TS values.\n",
    "\n",
    "unaggregated_data = np.zeros((ts_values.shape[0], nr_species * 3))\n",
    "\n",
    "f_values = properties_table[1, :][np.newaxis, :]\n",
    "rps_values = properties_table[2, :][np.newaxis, :]\n",
    "\n",
    "for i in range(nr_species):\n",
    "    f_value = f_values[0, i]\n",
    "    f_array = np.tile(f_value, (np.shape(ts_values)[0])).astype(object)\n",
    "\n",
    "    rps_value = rps_values[0, i]\n",
    "    rps_array = np.tile(rps_value, (np.shape(ts_values)[0])).astype(object)\n",
    "\n",
    "    unaggregated_data[:, i * 3] = ts_values[:, i]\n",
    "    unaggregated_data[:, i * 3 + 1] = f_array\n",
    "    unaggregated_data[:, i * 3 + 2] = rps_array\n",
    "\n",
    "unaggregated_data = unaggregated_data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating the dataset to represent sections of the forest comprising 5 adjacent sampling points each.\n",
    "\n",
    "data = np.zeros((unaggregated_data.shape[0] // 5, nr_species * 3))\n",
    "\n",
    "for i in range(len(data)):\n",
    "    for j in range(nr_species):\n",
    "        start_index = i * 5\n",
    "        end_index = start_index + 4\n",
    "        \n",
    "        data[i, j*3] = np.sum(unaggregated_data[start_index:end_index+1, j*3].astype(float))\n",
    "        data[i, j*3+1] = unaggregated_data[start_index, j*3+1]\n",
    "        data[i, j*3+2] = unaggregated_data[start_index, j*3+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell perform normalization on the TS values so that they are projected on the interval [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = normalize_TS(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating estimates <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell loads the machine learning models, namely Gradient Boosting Regressors, each fitted to predict the extent of browsing on a different species within the forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for i in range(nr_species):\n",
    "    models.append(joblib.load(f'./Models/gb_{i}.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell generates estimates of browsing extent for each of the species in each of the forest sections represented in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The value to predict if there was no supply from a given species within a section of the forest\n",
    "# (and consequently no possibility of browsing):\n",
    "noSupply_value = -0.00001\n",
    "\n",
    "section_estimates = np.zeros((len(data), nr_species))\n",
    "\n",
    "for i in range(nr_species):\n",
    "    predicted_browsing = models[i].predict(data)\n",
    "    \n",
    "    section_estimates[:, i] = models[i].predict(data)\n",
    "\n",
    "section_estimates = adjust_predictions(section_estimates, data, noSupply_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell calculates the overall estimated browsing extent on each of the species within the forest.\n",
    "\n",
    "This is done by summing the estimated browsing extents in each of the sections weighted by the contribution of the section to the overall number of shoots offered by a given species within the whole forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_estimates = np.zeros((1, nr_species))\n",
    "\n",
    "for sp in range(nr_species):\n",
    "    total_shoots = np.sum(data[:, sp*3])\n",
    "\n",
    "    if total_shoots != 0:\n",
    "\n",
    "        section_contributions = [data[section, sp*3] / total_shoots for section in range(len(data))]\n",
    "\n",
    "        weighted_estimates = [contribution * section_estimates[index, sp] for index, contribution in enumerate(section_contributions)]\n",
    "\n",
    "        forest_estimates[0, sp] = sum(weighted_estimates)\n",
    "\n",
    "    else:\n",
    "        forest_estimates[0, sp] = noSupply_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Displaying results <a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "The results of the forecast can be found below. The first cell prints them, the second saves them in a .csv file in the same folder as this notebook, named `browsing_forecast.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECIES             \tTOTAL SHOOTS\tFORECAST\n",
      "Unknown             \t           6\t   66.7%\n",
      "Quercus petraea     \t         165\t    7.8%\n",
      "Quercus cerris      \t          70\t    0.0%\n",
      "Fraxinus excelsior  \t           0\t     NaN\n",
      "Fraxinus ornus      \t         543\t    7.3%\n",
      "Carpinus betulus    \t           3\t    8.3%\n",
      "Fagus sylvatica     \t           0\t     NaN\n",
      "Acer pseudoplatanus \t          38\t    0.0%\n",
      "Acer platanoides    \t           0\t     NaN\n",
      "Acer campestre      \t          84\t    2.3%\n",
      "Pinus sylvestris    \t           0\t     NaN\n",
      "Robinia pseudoacacia\t          13\t    5.8%\n",
      "Ligustrum vulgare   \t         473\t   30.9%\n",
      "Crataegus monogyna  \t         624\t   11.5%\n",
      "Cornus mas          \t         135\t   14.5%\n",
      "Cornus sanguinea    \t           0\t     NaN\n",
      "Prunus spinosa      \t         341\t    4.6%\n",
      "Rubus fruticosus    \t          59\t    2.6%\n",
      "Rosa canina         \t         333\t    7.7%\n",
      "Acer tataricum      \t          58\t   11.9%\n",
      "Prunus avium        \t           0\t     NaN\n",
      "Corylus avellana    \t           0\t     NaN\n",
      "Ulmus minor         \t           0\t     NaN\n",
      "Sorbus aucuparia    \t           0\t     NaN\n",
      "Pyrus pyraster      \t         180\t   37.8%\n",
      "Euonymus verrucosus \t           0\t     NaN\n",
      "Quercus pubescens   \t          41\t    9.3%\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"SPECIES\":<20}\\t{\"TOTAL SHOOTS\":>12}\\t{\"FORECAST\":>8}')\n",
    "\n",
    "for index, sp in enumerate(species.tolist()):\n",
    "    forecast = forest_estimates[0, index]\n",
    "\n",
    "    total_shoots = np.sum(ts_values[:, index])\n",
    "\n",
    "    if forecast < 0:\n",
    "        print(f'{sp:<20}\\t{total_shoots:>12.0f}\\t{\"NaN\":>8}')\n",
    "\n",
    "    else:\n",
    "        print(f'{sp:<20}\\t{total_shoots:>12.0f}\\t{f\"{forecast*100:.1f}%\":>8}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.zeros((nr_species, 3)).astype('object')\n",
    "\n",
    "output[:, 0] = species\n",
    "\n",
    "for index, sp in enumerate(species.tolist()):\n",
    "    forecast = forest_estimates[0, index]\n",
    "\n",
    "    total_shoots = np.sum(ts_values[:, index])\n",
    "\n",
    "    output[index, 1] = total_shoots\n",
    "\n",
    "    output[index, 2] = forecast\n",
    "\n",
    "output = np.vstack((['Species', 'Total shoots', 'Forecast'], output))\n",
    "\n",
    "np.savetxt('browsing_forecast.csv', output, delimiter=',', fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
